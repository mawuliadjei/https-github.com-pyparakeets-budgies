{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Template Notebook - v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook should serve as a template for the standard modelling we will all be using for as the base of version 1 development.\n",
    "\n",
    "The goal is for us to use the same predicted probabilities and classes to build different functions according the to tasks assigned to us.\n",
    "\n",
    "The notebook should be used as follows:\n",
    "1. Import all needed packages:\n",
    "2. Load Data\n",
    "3. Split Train and Test Sets\n",
    "4. Build and Run model\n",
    "5. Output predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In the case a Module Not Found error is thrown, it will automatically attempt to install all needed packages. You would have to rerun the import package cell again after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def install_packages():\n",
    "    !pip install pandas\n",
    "    !pip install numpy\n",
    "    !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import successful\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn import datasets\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import accuracy_score, f1_score\n",
    "    print('import successful')\n",
    "except ModuleNotFoundError:\n",
    "    print('forcing install of necessary packages. If you see this, rerun this cell to try again')\n",
    "    install_packages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load necessary data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we're starting off with is the standard breast cancer dataset that lends itself directly to binary classification modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using the simplest flavour of the ordinary least squares logistic regression in this case and no data transformation / scaling to maintain simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mawuliadjei/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section provides the basic outputs we will be using for function building as variables. They are as follows:\n",
    "1. predicted_probabilities: this is output of pre for which we will be performing optizations. This has two 'columns' where the values in index 0 are the probabilities for the class 0 and those in index 1 have probabilies for class 1\n",
    "2. sklearn_class_labels: this is the class label prediction computed by sklearn's density function\n",
    "3. naive_class_labels: this is the class label prediction computed by using a naïve 0.5 threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of predicted probabilties: (188, 2)\n"
     ]
    }
   ],
   "source": [
    "predicted_probabilities = clf.predict_proba(X_test)\n",
    "print('shape of predicted probabilties:', predicted_probabilities.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of model default class predicttions: (188,)\n"
     ]
    }
   ],
   "source": [
    "sklearn_class_labels = clf.predict(X_test)\n",
    "print('shape of model default class predicttions:', sklearn_class_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of naïve class predicttions: (188,)\n"
     ]
    }
   ],
   "source": [
    "naive_class_labels = np.where(predicted_probabilities[:,1] > 0.5, 1, 0)\n",
    "print('shape of naïve class predicttions:', naive_class_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy and F1 score of sklearn predicted classes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9680851063829787, 0.9752066115702479)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracy and F1 score of sklearn predicted classes')\n",
    "accuracy_score(sklearn_class_labels, y_test), f1_score(sklearn_class_labels, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy and F1 score of naive predicted classes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9680851063829787, 0.9752066115702479)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracy and F1 score of naive predicted classes')\n",
    "accuracy_score(naive_class_labels, y_test), f1_score(naive_class_labels, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_search_space(number_of_values: int =100) -> np.array:\n",
    "    return np.linspace(0,1,number_of_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_classes(predicted_probabilities: np.array,\n",
    "                    threshold: float,\n",
    "                    is_multidimensional: bool,\n",
    "                    target_class_index: int = None):\n",
    "    if is_multidimensional:\n",
    "        assert target_class_index is not None\n",
    "        assert len(predicted_probabilities) > 1\n",
    "    if is_multidimensional:\n",
    "        classes = np.where(predicted_probabilities[:,target_class_index] >= threshold, 1, 0)\n",
    "    else:\n",
    "        classes = np.where(predicted_probabilities >= threshold, 1, 0)\n",
    "    return classes    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = convert_classes(predicted_probabilities=predicted_probabilities,\n",
    "                          threshold=0.5, \n",
    "                          is_multidimensional=True,\n",
    "                          target_class_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9752066115702479, 0.9752066115702479, 0.9752066115702479)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(classes, y_test), precision_score(classes, y_test), recall_score(classes, y_test),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_thresholds(predicted_probabilities: np.array,\n",
    "                       is_multidimensional: bool,\n",
    "                       search_space: np.array, # this should by type unioned with lists\\\n",
    "                       y_test: np.array,\n",
    "                       target_class_index: int = None):\n",
    "    f1_scores, precision_scores, recall_scores = [], [], []\n",
    "    for i in search_space:\n",
    "        classes = convert_classes(predicted_probabilities=predicted_probabilities,\n",
    "                                  threshold=i, \n",
    "                                  is_multidimensional=is_multidimensional,\n",
    "                                  target_class_index=target_class_index)\n",
    "        f1_scores.append(f1_score(classes, y_test))\n",
    "        precision_scores.append(precision_score(classes, y_test))\n",
    "        recall_scores.append(recall_score(classes, y_test))\n",
    "    best_f1_index, best_precision_index, best_recall_index = f1_scores.index(max(f1_scores)), precision_scores.index(max(precision_scores)), recall_scores.index(max(recall_scores))\n",
    "    best_f1_threshold, best_precision_threshold, best_recall_threshold = search_space[best_f1_index], search_space[best_precision_index], search_space[best_recall_index]\n",
    "    return best_f1_threshold, best_precision_threshold, best_recall_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mawuliadjei/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.15151515151515152, 0.0, 0.8383838383838385)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_thresholds(predicted_probabilities=predicted_probabilities,\n",
    "                    search_space=generate_search_space(),\n",
    "                    y_test=y_test,\n",
    "                  is_multidimensional=True,\n",
    "                  target_class_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_f1(predicted_probabilities: np.array,\n",
    "                       is_multidimensional: bool,\n",
    "                       search_space: np.array, # this should by type unioned with lists\\\n",
    "                       y_test: np.array,\n",
    "                       target_class_index: int = None):\n",
    "    f1_scores = []\n",
    "    for i in search_space:\n",
    "        classes = convert_classes(predicted_probabilities=predicted_probabilities,\n",
    "                                  threshold=i, \n",
    "                                  is_multidimensional=is_multidimensional,\n",
    "                                  target_class_index=target_class_index)\n",
    "        f1_scores.append(f1_score(classes, y_test))\n",
    "    best_f1_score = max(f1_scores)\n",
    "    best_f1_index = f1_scores.index(best_f1_score)\n",
    "    best_f1_threshold = search_space[best_f1_index]\n",
    "    print(f'best f1 score: {best_f1_score} occurs at threshold {best_f1_threshold}')\n",
    "    return best_f1_score, best_f1_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_precision(predicted_probabilities: np.array,\n",
    "                       is_multidimensional: bool,\n",
    "                       search_space: np.array, # this should by type unioned with lists\\\n",
    "                       y_test: np.array,\n",
    "                       target_class_index: int = None):\n",
    "    precision_scores = []\n",
    "    for i in search_space:\n",
    "        classes = convert_classes(predicted_probabilities=predicted_probabilities,\n",
    "                                  threshold=i, \n",
    "                                  is_multidimensional=is_multidimensional,\n",
    "                                  target_class_index=target_class_index)\n",
    "        precision_scores.append(precision_score(classes, y_test))\n",
    "    best_precision_score = max(precision_scores)\n",
    "    best_precision_index = precision_scores.index(best_precision_score)\n",
    "    best_precision_threshold = search_space[best_precision_index]\n",
    "    print(f'best precision score: {best_precision_score} occurs at threshold {best_precision_threshold}')\n",
    "    return best_precision_score, best_precision_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_recall(predicted_probabilities: np.array,\n",
    "                       is_multidimensional: bool,\n",
    "                       search_space: np.array, # this should by type unioned with lists\\\n",
    "                       y_test: np.array,\n",
    "                       target_class_index: int = None):\n",
    "    recall_scores = []\n",
    "    for i in search_space:\n",
    "        classes = convert_classes(predicted_probabilities=predicted_probabilities,\n",
    "                                  threshold=i, \n",
    "                                  is_multidimensional=is_multidimensional,\n",
    "                                  target_class_index=target_class_index)\n",
    "        recall_scores.append(recall_score(classes, y_test))\n",
    "    best_recall_score = max(recall_scores)\n",
    "    best_recall_index = recall_scores.index(best_recall_score)\n",
    "    best_recall_threshold = search_space[best_recall_index]\n",
    "    print(f'best recall score: {best_recall_score} occurs at threshold {best_recall_threshold}')\n",
    "    return best_recall_score, best_recall_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best recall score: 1.0 occurs at threshold 0.8383838383838385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 0.8383838383838385)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_recall(predicted_probabilities=predicted_probabilities,\n",
    "                    search_space=generate_search_space(),\n",
    "                    y_test=y_test,\n",
    "                  is_multidimensional=True,\n",
    "                  target_class_index=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
