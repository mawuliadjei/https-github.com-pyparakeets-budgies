{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Template Notebook - v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook should serve as a template for the standard modelling we will all be using for as the base of version 1 development.\n",
    "\n",
    "The goal is for us to use the same predicted probabilities and classes to build different functions according the to tasks assigned to us.\n",
    "\n",
    "The notebook should be used as follows:\n",
    "1. Import all needed packages:\n",
    "2. Load Data\n",
    "3. Split Train and Test Sets\n",
    "4. Build and Run model\n",
    "5. Output predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In the case a Module Not Found error is thrown, it will automatically attempt to install all needed packages. You would have to rerun the import package cell again after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def install_packages():\n",
    "    !pip install pandas\n",
    "    !pip install numpy\n",
    "    !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "import successful\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn import datasets\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import precision_score, recall_score, precision_recall_curve\n",
    "    print('import successful')\n",
    "except ModuleNotFoundError:\n",
    "    print('forcing install of necessary packages. If you see this, rerun this cell to try again')\n",
    "    install_packages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load necessary data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we're starting off with is the standard breast cancer dataset that lends itself directly to binary classification modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using the simplest flavour of the ordinary least squares logistic regression in this case and no data transformation / scaling to maintain simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section provides the basic outputs we will be using for function building as variables. They are as follows:\n",
    "1. predicted_probabilities: this is output of pre for which we will be performing optizations. This has two 'columns' where the values in index 0 are the probabilities for the class 0 and those in index 1 have probabilies for class 1\n",
    "2. sklearn_class_labels: this is the class label prediction computed by sklearn's density function\n",
    "3. naive_class_labels: this is the class label prediction computed by using a naïve 0.5 threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "shape of predicted probabilties: (188, 2)\n"
     ]
    }
   ],
   "source": [
    "predicted_probabilities = clf.predict_proba(X_test)\n",
    "print('shape of predicted probabilties:', predicted_probabilities.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "shape of model default class predicttions: (188,)\n"
     ]
    }
   ],
   "source": [
    "sklearn_class_labels = clf.predict(X_test)\n",
    "print('shape of model default class predicttions:', sklearn_class_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "shape of naïve class predicttions: (188,)\n"
     ]
    }
   ],
   "source": [
    "naive_class_labels = np.where(predicted_probabilities[:,1] > 0.5, 1, 0)\n",
    "print('shape of naïve class predicttions:', naive_class_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Recall score of sklearn predicted classes\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9752066115702479"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "print('Recall score of sklearn predicted classes')\n",
    "recall_score(sklearn_class_labels, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Recall score of naive predicted classes\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9752066115702479"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "print('Recall score of naive predicted classes')\n",
    "recall_score(naive_class_labels, y_test)"
   ]
  },
  {
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, threshold = precision_recall_curve(y_test, predicted_probabilities[:,1])\n",
    "pr = pd.DataFrame({'threshold': threshold, 'precision': precision[:-1], 'recall': recall[:-1]})"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 52,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     threshold  precision    recall\n",
       "0     0.212003   0.960317  1.000000\n",
       "1     0.255675   0.960000  0.991736\n",
       "2     0.289581   0.959677  0.983471\n",
       "3     0.352528   0.959350  0.975207\n",
       "4     0.484092   0.967213  0.975207\n",
       "..         ...        ...       ...\n",
       "121   0.999457   1.000000  0.041322\n",
       "122   0.999527   1.000000  0.033058\n",
       "123   0.999543   1.000000  0.024793\n",
       "124   0.999698   1.000000  0.016529\n",
       "125   0.999978   1.000000  0.008264\n",
       "\n",
       "[126 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>threshold</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.212003</td>\n      <td>0.960317</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.255675</td>\n      <td>0.960000</td>\n      <td>0.991736</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.289581</td>\n      <td>0.959677</td>\n      <td>0.983471</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.352528</td>\n      <td>0.959350</td>\n      <td>0.975207</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.484092</td>\n      <td>0.967213</td>\n      <td>0.975207</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>121</th>\n      <td>0.999457</td>\n      <td>1.000000</td>\n      <td>0.041322</td>\n    </tr>\n    <tr>\n      <th>122</th>\n      <td>0.999527</td>\n      <td>1.000000</td>\n      <td>0.033058</td>\n    </tr>\n    <tr>\n      <th>123</th>\n      <td>0.999543</td>\n      <td>1.000000</td>\n      <td>0.024793</td>\n    </tr>\n    <tr>\n      <th>124</th>\n      <td>0.999698</td>\n      <td>1.000000</td>\n      <td>0.016529</td>\n    </tr>\n    <tr>\n      <th>125</th>\n      <td>0.999978</td>\n      <td>1.000000</td>\n      <td>0.008264</td>\n    </tr>\n  </tbody>\n</table>\n<p>126 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "class ThresholdOptimizer:\n",
    "    def __init__(self, y_true, probas_pred, **kwargs):\n",
    "        precision, recall, threshold = precision_recall_curve(y_true, probas_pred, **kwargs)\n",
    "        self.best_precision_threshold = threshold[np.argmax(precision)-1]\n",
    "        self.best_recall_threshold = threshold[::-1][np.argmax(recall[::-1])-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.2120027616991124"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "# example\n",
    "optimizer = ThresholdOptimizer(y_test, predicted_probabilities[:,1])\n",
    "optimizer.best_recall_threshold"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}